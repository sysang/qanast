{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8387c14b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from typing import Any, List, Mapping, Optional\n",
    "import json\n",
    "\n",
    "import requests\n",
    "\n",
    "from operator import itemgetter\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "from langchain.llms.base import LLM\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "535792a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLLM(LLM):\n",
    "    max_tokens: int\n",
    "    api_url: str\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"custom\"\n",
    "\n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> str:\n",
    "        if stop is not None:\n",
    "            raise ValueError(\"stop kwargs are not permitted.\")\n",
    "\n",
    "        headers = { 'Content-Type' : 'application/json' }\n",
    "\n",
    "        # prompt_tpl = f\"<s>[INST] <<SYS>>\\n You are a helpful, respectful and honest assistant. \\\n",
    "        # Your answer is always as concise as possible, while being informative, sufficient. \\\n",
    "        # Please ensure that your responses are truthful, inspiring, positive. Please do not \\\n",
    "        # response to question thas is inappropriate or contradictory. If you don't know the \\\n",
    "        # answer to a question, please don't share false information\\n<</SYS>>\\n\\n {prompt} [/INST]\"\n",
    "\n",
    "        context = \"\"\"OpenAI CEO Sam Altman has announced internally that the company is targeting $1.3 billion in annual revenue, according to The Information.\n",
    "That's 30 percent more than the $1 billion in annual revenue leaked over the summer, which was already said to have exceeded investor expectations. The new figure suggests more than $100 million in monthly revenue.\n",
    "The biggest revenue driver is subscriptions to ChatGPT Plus. Last year, without the ChatGPT Plus offering, OpenAI had revenue of only $28 million, with a loss of $540 million, according to The Information.\n",
    "Due to the increase in revenue and rapid growth in recent months, OpenAI is estimated to have a new valuation of up to $90 billion. The goal is for employees to be able to sell their shares to outside investors at that level.\"\"\"\n",
    "\n",
    "        question = \"does annual revenue meet investor expectations? Yes or no?\"\n",
    "\n",
    "        prompt_tpl = f\"<s>[INST] <<SYS>>\\n You are a helpful, informative assistant. \\\n",
    "        Your answer is always as concise as possible. If you don't know the \\\n",
    "        answer to a question, please don't share false information\\n<</SYS>>\\n\\nGive short answer for the \\\n",
    "        question based only on the following context:\\n{context}\\n\\n Question: {question}[/INST]\"\n",
    "\n",
    "        print(\"[DEBUG] prompt: \", prompt)\n",
    "\n",
    "        data = {\n",
    "            'prompt': prompt,\n",
    "            \"stop\": [\"</s>\"],\n",
    "            \"max_tokens\": self.max_tokens\n",
    "        }\n",
    "        r = requests.post(\n",
    "            self.api_url,\n",
    "            headers=headers,\n",
    "            data=json.dumps(data),\n",
    "            timeout=1200)\n",
    "\n",
    "        response_data = r.json()\n",
    "\n",
    "        return response_data['choices'][0]['text']\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self) -> Mapping[str, Any]:\n",
    "        \"\"\"Get the identifying parameters.\"\"\"\n",
    "        return {\n",
    "            \"max_tokens\": self.max_tokens,\n",
    "            \"api_url\": self.api_url\n",
    "        }\n",
    "\n",
    "model = CustomLLM(max_tokens=500, api_url=\"http://192.168.58.9:3000/v1/completions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b378cc8f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='[INST] <<SYS>>You are a helpful chatbot <</SYS>>'),\n",
       " HumanMessage(content='[INST] What is your name? [/INST]')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"[INST] <<SYS>>You are a helpful chatbot <</SYS>>\"),\n",
    "     MessagesPlaceholder(variable_name=\"memory\"),\n",
    "    (\"human\", \"[INST] {input} [/INST]\")\n",
    "])\n",
    "messages = prompt.format_messages(\n",
    "    input=\"What is your name?\",\n",
    "    memory=[],\n",
    ")\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cda5777a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'hi im bob', 'memory': []}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "chain = RunnablePassthrough.assign(\n",
    "    memory=RunnableLambda(memory.load_memory_variables) | itemgetter(\"history\")\n",
    ")\n",
    "inputs = {\"input\": \"hi im bob\"}\n",
    "chain.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "685d062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnablePassthrough.assign(\n",
    "    memory=RunnableLambda(memory.load_memory_variables) | itemgetter(\"history\")\n",
    ") | prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c5394d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] prompt:  System: [INST] <<SYS>>You are a helpful chatbot <</SYS>>\n",
      "Human: [INST] hi im bob [/INST]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"  Hello Bob! *smiling* It's nice to meet you. Is there something I can help you with or would you like to chat?\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {\"input\": \"hi im bob\"}\n",
    "response = chain.invoke(inputs)\n",
    "memory.save_context(inputs, {\"output\": response})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a004ee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"input\": \"please tell me my name\"}\n",
    "response = chain.invoke(inputs)\n",
    "memory.save_context(inputs, {\"output\": response})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdd72c90",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] prompt:  System: [INST] <<SYS>>You are a helpful chatbot <</SYS>>\n",
      "Human: hi im bob\n",
      "AI:   Hello Bob! *smiling* It's nice to meet you. Is there something I can help you with or would you like to chat?\n",
      "Human: [INST] what is large language model? [/INST]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"  Ah, a great question, Bob! A Large Language Model (LLM) is a type of artificial intelligence (AI) model that is trained on vast amounts of text data to generate language outputs that are coherent and natural-sounding. These models are designed to learn the patterns and structures of language, allowing them to produce text that is often indistinguishable from human-generated content.\\n\\nLLMs have been around for a while, but they've gained significant attention in recent years due to their impressive capabilities and potential applications. Some of the key features of LLMs include:\\n\\n1. **Generative capacity**: LLMs can generate text, images, or even audio, based on the input they receive. This makes them useful for a wide range of applications, such as language translation, content creation, and chatbots like me!\\n2. **Improved accuracy**: As LLMs are trained on larger datasets, they become increasingly accurate in their predictions and generation capabilities. This is because they can learn from more diverse and extensive examples of language use.\\n3. **Increased efficiency**: LLMs can process and generate text at scale, making them faster and more efficient than traditional machine learning models. This is especially useful for applications where large amounts of text need to be processed quickly, such as in natural language processing tasks.\\n4. **Flexibility**: LLMs can be fine-tuned for specific tasks or domains, allowing them to adapt to different contexts and applications. For example, an LLM could be trained to generate medical text, legal documents, or even creative writing.\\n5. **Continual improvement**: As new data becomes available, LLMs can continue to learn and improve their performance. This means that they can stay up-to-date with the latest language trends and developments, allowing them to generate more accurate and relevant content over time.\\n\\nOverall, Large Language Models are an exciting area of research and development in the field of natural language processing. They have the potential to revolutionize many industries, from healthcare to entertainment, by enabling faster and more efficient communication, as well as creating new forms of creative content.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {\"input\": \"what is large language model?\"}\n",
    "response = chain.invoke(inputs)\n",
    "memory.save_context(inputs, {\"output\": response})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51cbeac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] prompt:  System: [INST] <<SYS>>You are a helpful chatbot <</SYS>>\n",
      "Human: hi im bob\n",
      "AI:   Hello Bob! *smiling* It's nice to meet you. Is there something I can help you with or would you like to chat?\n",
      "Human: what is large language model?\n",
      "AI:   Ah, a great question, Bob! A Large Language Model (LLM) is a type of artificial intelligence (AI) model that is trained on vast amounts of text data to generate language outputs that are coherent and natural-sounding. These models are designed to learn the patterns and structures of language, allowing them to produce text that is often indistinguishable from human-generated content.\n",
      "\n",
      "LLMs have been around for a while, but they've gained significant attention in recent years due to their impressive capabilities and potential applications. Some of the key features of LLMs include:\n",
      "\n",
      "1. **Generative capacity**: LLMs can generate text, images, or even audio, based on the input they receive. This makes them useful for a wide range of applications, such as language translation, content creation, and chatbots like me!\n",
      "2. **Improved accuracy**: As LLMs are trained on larger datasets, they become increasingly accurate in their predictions and generation capabilities. This is because they can learn from more diverse and extensive examples of language use.\n",
      "3. **Increased efficiency**: LLMs can process and generate text at scale, making them faster and more efficient than traditional machine learning models. This is especially useful for applications where large amounts of text need to be processed quickly, such as in natural language processing tasks.\n",
      "4. **Flexibility**: LLMs can be fine-tuned for specific tasks or domains, allowing them to adapt to different contexts and applications. For example, an LLM could be trained to generate medical text, legal documents, or even creative writing.\n",
      "5. **Continual improvement**: As new data becomes available, LLMs can continue to learn and improve their performance. This means that they can stay up-to-date with the latest language trends and developments, allowing them to generate more accurate and relevant content over time.\n",
      "\n",
      "Overall, Large Language Models are an exciting area of research and development in the field of natural language processing. They have the potential to revolutionize many industries, from healthcare to entertainment, by enabling faster and more efficient communication, as well as creating new forms of creative content.\n",
      "Human: [INST] do you know my name? [/INST]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"  AI: Oh, Bob! *chuckles* I'm just an AI, I don't have access to personal information like your name. But it's nice to chat with you, Bob! Is there something else you would like to talk about or ask?\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {\"input\": \"what did I ask you recently?\"}\n",
    "response = chain.invoke(inputs)\n",
    "memory.save_context(inputs, {\"output\": response})\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "md,ipynb",
   "main_language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
