version: '3'

tasks:
  meili_api_get_indexes:
    cmds:
      - xh http://localhost:7700/indexes

  llm3:
    cmds:
      - docker exec -d llm3 zsh -c '/usr/bin/python3 -m llama_cpp.server --port 3000 --host "0.0.0.0" --model /models/llama-2-7b-chat.ggmlv3.q3_K_L.gguf --n_gpu_layers 35'

  translation:
    cmds:
      - docker exec -d -u root mytransformers bash -c 'uvicorn --host "0.0.0.0" --port 3100 main:app'

  build_bot:
    cmds:
      - docker exec -it -u tiger ailab zsh -c "source ~/.zshrc && cd /workspace/qna-assistant && npm run build"

  start_dev_bot:
    cmds:
      - docker exec -it -u tiger ailab zsh -c "source ~/.zshrc && cd /workspace/qna-assistant && npm run dev"

  test_bot:
    cmds:
      - docker exec -it -u tiger ailab zsh -c "source ~/.zshrc && cd /workspace/qna-assistant && npm test"

